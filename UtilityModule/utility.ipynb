# basic libraries
import pandas as pd
import numpy as np
import cv2,os
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# sklearn and colab libraries
from sklearn.model_selection import train_test_split,StratifiedShuffleSplit
from sklearn.metrics import hamming_loss,jaccard_similarity_score,accuracy_score,confusion_matrix
from sklearn.metrics import roc_auc_score,roc_curve
from google.colab import drive
import io,pickle

#tensorflow libraries
import copy

# sme mathmatical libraries.
from time import time
from random import random
from PIL import Image
from tqdm import tqdm_notebook
import time,math,operator
import warnings



# utility functions
def load_data():
  """ Loading up of the data return data"""
  drive.mount('/content/gdrive')
  data = pd.read_csv('/content/gdrive/My Drive/CaseStudy3/severstal-steel-defect-detection_unzip/train.csv')
  print("Total train images given",data.shape)
  return data

def add_undefected_images(data): 
  """ Takes the dataframe as input and retur the updated datframe which contain both defected and iundefected images """ 
  # Undefcted_data = pd.DataFrame()
  # calculate sum of the pixels for the mask per class id
  print("Binary column added....")
  # calculate the sum of the pixels of the given mask so find the area of the defect. 1 pixels = 1 unit area.
  data['mask_pixel_sum'] = data.apply(lambda x: rle2mask(x['EncodedPixels']).sum(),axis = 1)
  count = 0
  folder = "/content/gdrive/My Drive/CaseStudy3/severstal-steel-defect-detection_unzip/train_images"
  # count the image file names for the given directory
  filename_list = []
  for filename in os.listdir(folder):
      if filename not in data['ImageId'].values:
          filename_list.append(filename)
      count+=1
  # print the total number of images present in the directory.
  print(count)
  print("Total images from the directory : 12568")
  print("Undefected images from the directory: 5902")
  # creating the dictionary that contain the undefected images details.
  dictionary = {}
  dictionary.update({"ImageId":filename_list,"ClassId":0,"EncodedPixels":0})
  data_undefected = pd.DataFrame(dictionary)
  # concatinate the the defected and undefected images in the single dataframe called data.
  data = pd.concat([data,data_undefected])
  print("Final data which contain repeated imagesId tags becasue these images contain multiple type defects :",data.shape[0]-12568)
  data = data.sample(frac=1,random_state=42).reset_index(drop=True)
  print("Suffled final data shape : ",data.shape)
  return data

# Addingbinaary label : 
def add_binary_label(data):
  """ Adding the BinaryData column in the dataframe which will be useful for binary classification."""
  binary_data = []
  # This loop is assigning the binsary data column 0 when classid is zero otherwise 1.
  for i in range(len(data["ClassId"])):
    if data["ClassId"][i] == 0:
      binary_data.append(0)
    else:
      binary_data.append(1)  
  data["BinaryData"] =  binary_data   
  data.reset_index(inplace=True)
  # Code to rename the index as ID.
  data.rename(columns={'index': 'ID'}, inplace=True)
  return data  

def EDA_on_area(train_df):
  class_ids = [1,2,3,4]
  mask_count_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0.0)]['mask_pixel_sum'].count() for class_id in class_ids]
  pixel_sum_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0.0)]['mask_pixel_sum'].sum() for class_id in class_ids]
  return [mask_count_per_class,pixel_sum_per_class] 

"""Utility functions"""
def Defect_images(dataset,defect_type,start,end):
    """Showing the images of different defect type. added to do the EDA part."""
    print(f"                                             Defect Type {defect_type}")
    image_1 = dataset[dataset["ClassId"]==defect_type][start:end]["ImageId"].values
    for i in image_1:
      print("Image id : ",i)
      plt.figure(figsize=(16,4))
      # Loading the images one by one from the directory.
      image_read = cv2.imread('/content/gdrive/My Drive/CaseStudy3/severstal-steel-defect-detection_unzip/train_images/'+i)
      image_read = cv2.cvtColor(image_read, cv2.COLOR_BGR2RGB)
      # show the graph.
      plt.imshow(image_read) 


def Class_present_in_dataset(dataset):
    """ Function to do the EDA , defected class number in the train dataset."""
    plt.figure(figsize=(12,5))
    keys_ = dataset['ClassId'].value_counts().to_dict().keys()
    values_ = dataset['ClassId'].value_counts().to_dict().values()
    sns.barplot([i for i in keys_],[i for i in values_])
    plt.title("NUMBER OF TIMES DEFECTED CLASS PRESENT IN TRAIN DATASET")
    plt.xlabel("CLASSES")
    plt.ylabel("DEFFECT CLASS COUNT")
    plt.show() 
    
def No_of_defect_type_in_image(dataset):
    from collections import Counter
    # Create a graph which show in which class number of multiple defect images are present.
    plt.figure(figsize=(12,5))
    plt.title("GRAPH BETWEEN MULTIPLE DEFECT IMAGES/CLASSES ")
    keys_ = Counter([i for i in dataset['ImageId'].value_counts().to_dict().values()]).keys()
    values_ = Counter([i for i in dataset['ImageId'].value_counts().to_dict().values()]).values()
    sns.barplot([i for i in keys_],[i for i in values_])
    for key,value in enumerate([i for i in values_][::-1],0):
        plt.annotate(value,(key,value+100))
    plt.yticks([i for i in range(0,10000,500)])
    plt.xlabel("NO OF DEFECTS TYPE IN AN IMAGE") 
    plt.ylabel("COUNT OF IMAGES THAT HAVE 1/2/3 TYPE OF DEFECT") 
    plt.show()   

def mask2rle(img):
    '''
    img: numpy array, 1 - mask, 0 - background
    Returns run length as string formated
    '''
    pixels= img.T.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)
 
def rle2mask(mask_rle, shape=(1600,256)):
    '''
    mask_rle: run-length as string formated (start length)
    shape: (width,height) of array to return 
    Returns numpy array, 1 - mask, 0 - background

    '''
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape).T     

def load_rgb(img_path):
  # Load the image adn normailize it by dicing by 255.
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  img = img.astype(np.float32) / 255.
  # Retur nthe image.
  return img   


def preprocess_multilabel_label(data):  
  """This function preprocess the input data for the multilabel model i.e. model 5"""
  defect1 = []
  defect2 = []
  defect3 = []
  defect4 = []
  multilabel_df = data[data["ClassId"] != 0]
  for cls in multilabel_df["ClassId"].values:
    if cls == 1:
      defect1.append(1)
      defect2.append(0)
      defect3.append(0)
      defect4.append(0)
    elif( cls == 2):
      defect1.append(0)
      defect2.append(1)
      defect3.append(0)
      defect4.append(0)
    elif( cls == 3):
      defect1.append(0)
      defect2.append(0)
      defect3.append(1)
      defect4.append(0)
    elif( cls == 4):
      defect1.append(0)
      defect2.append(0)
      defect3.append(0)
      defect4.append(1) 
  multilabel_df["defect1"] = defect1
  multilabel_df["defect2"] = defect2
  multilabel_df["defect3"] = defect3
  multilabel_df["defect4"] = defect4 
  return multilabel_df  
  
def Model_3_thresholding_y_predicted(y_predicted,thresholds):
  """This function apply the different .5 thresholding for Multilabel model Model 3 so that we can apply hamming loss,
   jaccard score ,accuracy score"""
  y_predicted_filtered = np.zeros((y_predicted.shape[0],4), dtype=int)
  for row,i in enumerate(y_predicted):
    for column,_ in enumerate(i):

      if i[0] > thresholds[0]:
        y_predicted_filtered[row][0] = 1
      if i[1] > thresholds[1]:
        y_predicted_filtered[row][1] = 1 
      if i[2] > thresholds[2]:
        y_predicted_filtered[row][2] = 1 
      if i[3] > thresholds[3]:
        y_predicted_filtered[row][3] = 1 

  return y_predicted_filtered  

def plot_confusion_matrix(test_y, predict_y):
    """Input Params : test_y, predict_y , This model is t genertate the confusion maetric,recall and precisio metrics"""
    C = confusion_matrix(test_y, predict_y,labels=[0,1])
    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j
    A =(((C.T)/(C.sum(axis=1))).T)
    #divid each element of the confusion matrix with the sum of elements in that column
    B =(C/C.sum(axis=0))

    plt.figure(figsize=(20,4))
    labels = [1,2]
    # representing A in heatmap format
    cmap=sns.light_palette("blue")
    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")
    
    plt.subplot(1, 3, 2)
    sns.heatmap(B, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Precision matrix")
    
    plt.subplot(1, 3, 3)
    # representing B in heatmap format
    sns.heatmap(A, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Recall matrix")
    
    plt.show() 
        
    

def Plot_AUC_Curve(y_test,prediction_list_1):
    prediction_list_dumb = [0 for _ in np.array(y_test)]
    random_auc = roc_auc_score(np.array(y_test),prediction_list_dumb)
    Intelligent_auc = roc_auc_score(np.array(y_test),prediction_list_1)
    # summarize scores
    print('No Skill: ROC AUC=%.3f' % (random_auc))
    print('Efficientb1 Deep Learned: ROC AUC=%.3f' % (Intelligent_auc))
    # calculate roc curves
    ns_fpr, ns_tpr, _ = roc_curve(np.array(y_test),prediction_list_dumb)
    lr_fpr, lr_tpr, _ = roc_curve(np.array(y_test),prediction_list_1)
    # plot the roc curve for the model
    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
    plt.plot(lr_fpr, lr_tpr, marker='.', label='Efficientb1 Deep Learned')
    # axis labels
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    # show the legend
    plt.legend()
    # show the plot
    plt.show()  
 


def Image_Visualizaton(row,column,predictions_tensor,test_dataset):
  """This function show the image visualization of the defect
  input : row,column which is nothing but sublot row, column and predictions list, dataset
  it's a duynamic finction you can visualize any number of subplot as you want."""
  fig, ax = plt.subplots(nrows=row, ncols=column,figsize=(30,25))
  # image_IDs = dataset[0:6]["ImageId"].values
  # for iter,image_id in enumerate(image_IDs,0):
  for iter,(batch_x, batch_y) in enumerate(test_dataset.take(6)):  
    for iterator,col in enumerate(ax[iter],0):
        if iterator ==0:
          # plot original images on column 1
          col.title.set_text("Original image of the industry")
          col.imshow(batch_x[0]) 
        elif (iterator ==1):
          # plot given mask images on column 2
          col.title.set_text("Defect trace given by industry")
          col.imshow(batch_y[0,:,:])
        else:
          # plot predicted images on column 3
          col.title.set_text("Defect predicted")          
          col.imshow(predictions_tensor[iter])
  plt.show()  

def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) \
            / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) 


def rle2maskResize(rle,shape = None):
    '''
    Copied from the kaggle competition kernel
    Generates masks for each image taking RLE as input
    Converts run length encoding to an image of shape defined uniform throughout segmentation models: 256x800
    Takes EncodedPixels as input, converts into 256x1600 mask and returns a resized mask image of size 256x800
    '''
    if (pd.isnull(rle))|(rle==''): # If the EncodedPixels string is empty an empty mask is returned
        return np.zeros(shape ,dtype=np.uint8)

    height= 256
    width = 1600
    mask= np.zeros( width*height ,dtype=np.uint8)

    array = np.asarray([int(x) for x in rle.split()])
    starts = array[0::2]-1 # The pixel array definition starts from 1 while array starts from 0
    lengths = array[1::2]  # The second element of EncodedPixels is the length denoting number of pixels in successive that are active (value = 1)
    for index, start in enumerate(starts):
        mask[int(start):int(start+lengths[index])] = 1 # Making 
    
    return mask.reshape((height,width),order='F')[::,::2] 

